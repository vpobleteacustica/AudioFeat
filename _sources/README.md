# Extracción de features en señales audio

## Resumen

> ¿Cómo dotar a un computador de capacidades de detección (activa) similares a las de los humanos?

> El `sonido` es el canal de comunicación más importante entre los `seres vivos`.

> La `audición` proporciona acceso a un mundo `sónico` infinito, por ejemplo, un `paisaje sonoro` donde existe la lluvia, el viento, los anfibios, las aves, los motores, la voz, el llanto, los gritos.

> La `percepción auditiva` es lo que permite dar significado a la información sonora entre la fuente del sonido y el auditor.

> La audición y la percepción funcionan de manera `sincrona`.

```{note}
Hearing and perception are often in synchrony in terms of sensation in human
beings
```

> Si tuviéramos una máquina que pudiera oír como lo hacen los seres humanos, qué esperaríamos que haga? Podría ser `detectar`, `localizar`, `idenficar` múltiples eventos sonoros que ocurren simultáneamente (`polifonía`).

## Enlaces de interés

https://joserzapata.github.io/courses/mineria-audio/descripcion_estadistica/

https://stackoverflow.com/questions/65986446/pyorch-applying-a-batch-of-filters-kernels-on-one-single-picture-using-conv2d

https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/

https://www.entechin.com/how-to-use-conv2d-in-pytorch/

https://devopedia.org/audio-feature-extraction

https://kornia.readthedocs.io/en/v0.4.0/tutorials/color_conversions.html

https://www.cs.rice.edu/~vo9/recognition/notebooks/image_processing_lab.html
